{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from config import DATA_MONTHLY_MEAN_NORMALIZED_FILE, DATA_CONSUMPTION_SEMI_PROCESSED_FILE, DATA_CONSUMPTION_PROCESSED_FILE, DATA_WEATHER_PROCESSED_FILE,  DATA_METADATA_PROCESSED_FILE, DATA_HOLIDAYS_PROCESSED_FILE, DATA_ISO_CONSUMPTION_PROCESSED_FILE, DATA_ENTHALPY_GRADIENTS_PROCESSED_FILE, DATA_SOLAR_GAINS_PROCESSED_FILE, DATA_GBM_CONSUMPTION_PROCESSED_FILE\n",
    "from lgbm_imputer import imputer\n",
    "import matplotlib\n",
    "from sklearn.model_selection import GroupShuffleSplit,TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_CONSUMPTION_SEMI_PROCESSED_FILE)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.drop_duplicates(['timestamp', 'smapee'])\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#important so we can do the timeseries split for validation data\n",
    "df['year'] = np.array(df['timestamp'].dt.year, dtype=np.uint16)\n",
    "df['dayofweek'] = np.array(df['timestamp'].dt.dayofweek, dtype=np.uint8)\n",
    "df['weekday'] = df['dayofweek'].apply(lambda x: 1 if 0<=x<5 else 0)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all in monthly data only for control group\n",
    "ids = df['ID_CEA'].unique()\n",
    "# for bid in ids:\n",
    "df_final = df#[(df['INTERVENTION'].isin(['1CONTROL','2CONTROL', '3CONTROL']))]\n",
    "df_final =  df_final.set_index('timestamp').resample('M').mean()\n",
    "df_final['CONSUMPTION_kWh'].plot()\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum =  0.50\n",
    "scaler = MinMaxScaler(feature_range=(minimum, 1))\n",
    "df_final['consumption_kWh_norm'] = scaler.fit_transform(df_final['CONSUMPTION_kWh'].values.reshape(-1, 1))\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['consumption_kWh_norm'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final['consumption_kWh_norm_2019'] = list(df_final['consumption_kWh_norm'][12:].values) + list(range(12))\n",
    "df_final.T.to_csv(DATA_MONTHLY_MEAN_NORMALIZED_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
