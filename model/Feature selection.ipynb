{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "from corr_plot import corrplot\n",
    "import numpy as np\n",
    "from lgbm_consumption_module import data_preprocessing_interventions, lgbm_regression_efecto_acumulado_con_linea_base_del_experimento\n",
    "import matplotlib\n",
    "from auxiliary import week_of_month, graph_check_cumulative_bsts, graph_check_gbm_dist, graph_check_gbm_timeseries, prepare_data_synthetic_bsts, prepare_data_control_bsts\n",
    "from sklearn.model_selection import GroupShuffleSplit,TimeSeriesSplit\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from causalimpact import CausalImpact\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.signal import savgol_filter as sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = data_preprocessing_interventions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sg(df, group, lag, diff):\n",
    "    p = 3\n",
    "    df['ISO_kWh_smooth_'+str(lag)] = 0.0\n",
    "    df['SG_kWh_smooth_'+str(lag)] = 0.0\n",
    "    df['DEG_C_kWh_smooth_'+str(lag)] = 0.0\n",
    "#     df['ISO_kWh_diff_'+str(lag)] = 0.0\n",
    "#     df['SG_kWh_diff_'+str(lag)] = 0.0\n",
    "#     df['DEG_C_kWh_diff_'+str(lag)] = 0.0\n",
    "    for si in df[group].unique():\n",
    "        index = df[group] == si\n",
    "        df.loc[index, 'ISO_kWh_smooth_'+str(lag)] = sg(df[index].ISO_kWh, lag, p)\n",
    "        df.loc[index, 'SG_kWh_smooth_'+str(lag)] = sg(df[index].SG_kWh, lag, p)\n",
    "        df.loc[index, 'DEG_C_kWh_smooth_'+str(lag)] = sg(df[index].DEG_C_kWh, lag, p)\n",
    "    return df\n",
    "#data_mean = add_sg(data_mean, 'INTERVENTION', 7, diff=1)\n",
    "data_mean = add_sg(data_mean, 'INTERVENTION', 29, diff=1)\n",
    "#data_mean = add_sg(data_mean, 'INTERVENTION', 89, diff=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lags(data, lag):\n",
    "    \n",
    "    df = data.copy()\n",
    "    df = df.set_index(['timestamp', 'INTERVENTION'])  # index\n",
    "    df = df.unstack().shift(lag)  # pull out the groups, shift with lag step=1\n",
    "    df = df.stack(dropna=False)\n",
    "    df.reset_index(inplace=True)  # stack the groups back, keep the missing values\n",
    "    \n",
    "    data['ISO_kWh_'+str(lag)] = df['ISO_kWh'] \n",
    "    data['SG_kWh_'+str(lag)] = df['SG_kWh'] \n",
    "    data['DEG_C_kWh_'+str(lag)] = df['DEG_C_kWh'] \n",
    "\n",
    "    return data\n",
    "data_mean = add_lags(data_mean, 3)\n",
    "data_mean = add_lags(data_mean, 7)\n",
    "data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr  = data_mean.corr()\n",
    "fig = plt.figure(figsize=(30,15))\n",
    "sns.heatmap(corr, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these we remove those that have a correaltion of less than 0.1 and more than 0.80\n",
    "1. month vs week of year: remove weekofyear\n",
    "2. month vs day of year: remove day of year\n",
    "3. empty_day_mean vs empty_day_sum: remove empty_day_sum\n",
    "4. full_day_sum vs full_day_mean: remove full_day_mean\n",
    "5. dayofweek vs weekday:  remove dayofweek\n",
    "6. experiment vs year: remove EXPERIMENT\n",
    "7. remove also: holiday, school holiday\n",
    "8. remove also DEC_HUM: it does not contribute too much\n",
    "9. we added lags but there was not improvement in the pearson correlation and such tehy were discarded\n",
    "10. we added also sav filter, for smooting and derivative. derivative and smotther of 3, 7, 29 and 89 days did not gave any results.\n",
    "11. we tried tha sav filer and those features with 29 worked verywell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#clean correalation plot\n",
    "ALL_NUMERICAL_FEATURES = [\n",
    "    'EMPTY_DAY_INT',\n",
    "    'FULL_DAY_INT',\n",
    "    'INCOME_SUM',\n",
    "    'FULL_DAY_SUM',\n",
    "    'INCOME_MEAN',\n",
    "    'EMPTY_DAY_MEAN',\n",
    "    'ISO_kWh',\n",
    "    'DEG_C_kWh',\n",
    "    'SG_kWh',\n",
    "    'ISO_kWh_smooth_29',\n",
    "    'SG_kWh_smooth_29',\n",
    "    'DEG_C_kWh_smooth_29'\n",
    "]\n",
    "\n",
    "ALL_CATEGORICAL_FEATURES = [\n",
    "    'teaching_time',\n",
    "    'weekday',\n",
    "    'month',\n",
    "    'year',\n",
    "]\n",
    "corr  = data_mean[['CONSUMPTION_kWh']+ALL_NUMERICAL_FEATURES+ALL_CATEGORICAL_FEATURES].corr()\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "sns.heatmap(corr, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data_mean[['CONSUMPTION_kWh']+ALL_NUMERICAL_FEATURES+ALL_CATEGORICAL_FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
