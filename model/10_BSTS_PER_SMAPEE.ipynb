{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from config import INTERVENTION_CALENDAR, DATA_CONSUMPTION_PROCESSED_FILE, DATA_WEATHER_PROCESSED_FILE,  DATA_METADATA_PROCESSED_FILE, DATA_HOLIDAYS_PROCESSED_FILE, DATA_ISO_CONSUMPTION_PROCESSED_FILE, DATA_ENTHALPY_GRADIENTS_PROCESSED_FILE, DATA_SOLAR_GAINS_PROCESSED_FILE, DATA_GBM_CONSUMPTION_PROCESSED_FILE\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from causalimpact import CausalImpact\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "real_consumption_df = pd.read_csv(DATA_CONSUMPTION_PROCESSED_FILE)\n",
    "real_consumption_df['timestamp'] = pd.to_datetime(real_consumption_df['timestamp'])\n",
    "weather_data_df = pd.read_csv(DATA_WEATHER_PROCESSED_FILE)\n",
    "weather_data_df['timestamp'] = pd.to_datetime(weather_data_df['timestamp'])\n",
    "metadata_df = pd.read_excel(DATA_METADATA_PROCESSED_FILE, sheets='SENSORS')[['smapee','INTERVENTION','ID_CEA', 'EXPERIMENT', 'TREATMENT', 'ID_SUBJECT', 'SALARY','BEDROOMS']]\n",
    "holidays_df = pd.read_csv(DATA_HOLIDAYS_PROCESSED_FILE)\n",
    "holidays_df['timestamp'] = pd.to_datetime(holidays_df['timestamp'])\n",
    "gradients_df = pd.read_csv(DATA_ENTHALPY_GRADIENTS_PROCESSED_FILE)\n",
    "gradients_df['timestamp'] = pd.to_datetime(gradients_df['timestamp'])\n",
    "solar_gains_df = pd.read_csv(DATA_SOLAR_GAINS_PROCESSED_FILE)\n",
    "solar_gains_df['timestamp'] = pd.to_datetime(solar_gains_df['timestamp'])\n",
    "iso_consumption_df = pd.read_csv(DATA_ISO_CONSUMPTION_PROCESSED_FILE)\n",
    "iso_consumption_df['timestamp'] = pd.to_datetime(iso_consumption_df['timestamp'])\n",
    "gbm_consumption_df = pd.read_csv(DATA_GBM_CONSUMPTION_PROCESSED_FILE)\n",
    "gbm_consumption_df['timestamp'] = pd.to_datetime(gbm_consumption_df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all\n",
    "# merge all the fields\n",
    "df = real_consumption_df.merge(metadata_df, left_on=['smapee', 'INTERVENTION'], right_on=['smapee', 'INTERVENTION'])\n",
    "df = df.merge(weather_data_df, left_on='timestamp', right_on='timestamp')\n",
    "df = df.merge(holidays_df, left_on='timestamp', right_on='timestamp')\n",
    "df = df.merge(gradients_df, left_on='timestamp', right_on='timestamp')\n",
    "df = df.merge(solar_gains_df, left_on=['timestamp','ID_CEA'], right_on=['timestamp','ID_CEA'])\n",
    "df = df.merge(iso_consumption_df, left_on=['timestamp','ID_CEA'], right_on=['timestamp','ID_CEA'])\n",
    "df = df.merge(gbm_consumption_df, left_on=['timestamp','smapee','INTERVENTION'], right_on=['timestamp','smapee', 'INTERVENTION'])\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, corrupted, INTERVENTION):\n",
    "    #let's get the data for the first experiment of sensors in VIEW\n",
    "    data_selection = df[(df['INTERVENTION']== INTERVENTION)&\n",
    "                            (~df['ID_SUBJECT'].isin(corrupted))]\n",
    "    #get groupdata (get mean so it is easier to compare to the control group)\n",
    "    data_mean1 = data_selection.groupby('timestamp')[['GBM_consumption_kWh',\n",
    "                                                      'consumption_kWh']].mean()\n",
    "    data_mean2 = data_selection.groupby('timestamp')[['solar_gain_Whm2',\n",
    "                                                      'DEG_C_kJperKg', \n",
    "                                                      'ISO_consumption_Whm2', \n",
    "                                                      'DEG_DEHUM_kJperKg',\n",
    "                                                      'Wind_ms',\n",
    "                                                      'teaching_time',\n",
    "                                                      'school_holiday',\n",
    "                                                      'holiday']].mean()\n",
    "    data_mean = data_mean1.merge(data_mean2, left_index=True, right_index=True)\n",
    "#     data_mean = data_mean2\n",
    "    data_mean['year'] = np.array(data_mean.index.year, dtype=np.uint16)\n",
    "    data_mean['month'] = np.array(data_mean.index.month, dtype=np.uint8) - 1\n",
    "    data_mean['dayofweek'] = np.array(data_mean.index.dayofweek, dtype=np.uint8)\n",
    "    data_mean['dayofyear'] = np.array(data_mean.index.dayofyear, dtype=np.uint16) - 1\n",
    "    data_mean['weekofyear'] = np.array(data_mean.index.weekofyear, dtype=np.uint8) - 1\n",
    "    data_mean['weekday'] = data_mean['dayofweek'].apply(lambda x: 1 if 0<=x<5 else 0)\n",
    "    data_mean.sort_index(inplace=True)\n",
    "\n",
    "    dict_info = {'y': data_mean['consumption_kWh'].values, \n",
    "                 'x1':data_mean['DEG_C_kJperKg'],\n",
    "                 'x2':data_mean['DEG_DEHUM_kJperKg'],\n",
    "                 'x3':data_mean['solar_gain_Whm2'],\n",
    "                 'x4':data_mean['ISO_consumption_Whm2'],\n",
    "                 'x5':data_mean['GBM_consumption_kWh'],\n",
    "                 'x6':data_mean['Wind_ms'],\n",
    "                 'x7':data_mean['teaching_time'],\n",
    "                 'x8':data_mean['school_holiday'],\n",
    "                 'x9':data_mean['holiday'],\n",
    "                 'x10':data_mean['month'],\n",
    "                 'x11':data_mean['dayofweek'],\n",
    "                 'x12':data_mean['weekday']}\n",
    "    data = pd.DataFrame(dict_info)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_control(df, corrupted, INTERVENTION):\n",
    "    #let's get the data for the first experiment of sensors in VIEW\n",
    "    data_selection = df[df['INTERVENTION']== INTERVENTION]\n",
    "\n",
    "    #get groupdata (get mean so it is easier to compare to the control group)\n",
    "    data_mean = data_selection.groupby('timestamp')[['consumption_kWh']].sum()\n",
    "    data_mean['year'] = np.array(data_mean.index.year, dtype=np.uint16)\n",
    "    data_mean['month'] = np.array(data_mean.index.month, dtype=np.uint8) - 1\n",
    "    data_mean['dayofweek'] = np.array(data_mean.index.dayofweek, dtype=np.uint8)\n",
    "    data_mean['dayofyear'] = np.array(data_mean.index.dayofyear, dtype=np.uint16) - 1\n",
    "    data_mean['weekofyear'] = np.array(data_mean.index.weekofyear, dtype=np.uint8) - 1\n",
    "    data_mean['weekday'] = data_mean['dayofweek'].apply(lambda x: 1 if 0<=x<5 else 0)\n",
    "    data_mean.sort_index(inplace=True)\n",
    "    \n",
    "    data_selection = df[(df['EXPERIMENT']== int(list(INTERVENTION)[0]))&\n",
    "                    (df['TREATMENT'] == 'CONTROL') &\n",
    "                    (~df['ID_SUBJECT'].isin(corrupted))]\n",
    "    data_mean1 = data_selection.groupby('timestamp')[['consumption_kWh']].sum()\n",
    "    \n",
    "    data_mean2 = data_mean.merge(data_mean1, left_index=True, right_index=True)\n",
    "    dict_info = {'y':data_mean2['consumption_kWh_x'], \n",
    "                 'x1':data_mean2['consumption_kWh_y']}\n",
    "    data = pd.DataFrame(dict_info)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check graph\n",
    "def graph(ci, end_intervention_date):\n",
    "    font = {'family' : 'Arial',\n",
    "            'size'   : 18}\n",
    "    ax = ci.plot(figsize = (6,8), end_intervention_date=end_intervention_date)\n",
    "    matplotlib.rc('font', **font)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOS TRATADOS EXPERIMENT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interventions = INTERVENTION_CALENDAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corrupted = ['S620','S638']\n",
    "experiment = 1\n",
    "intervention_data = interventions[experiment]\n",
    "for intervention in intervention_data[0]:\n",
    "    pre_period = intervention_data[1]\n",
    "    post_period = intervention_data[2]\n",
    "    end_intervention_date = intervention_data[3]\n",
    "    data = prepare_data(df, corrupted, intervention)\n",
    "    ci = CausalImpact(data, pre_period, post_period, prior_level_sd=None, standarize=True)\n",
    "    graph(ci, end_intervention_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted = ['S620','S638']\n",
    "experiment = 2\n",
    "intervention_data = interventions[experiment]\n",
    "for intervention in intervention_data[0]:\n",
    "    pre_period = intervention_data[1]\n",
    "    post_period = intervention_data[2]\n",
    "    end_intervention_date = intervention_data[3]\n",
    "    data = prepare_data(df, corrupted, intervention)\n",
    "    ci = CausalImpact(data, pre_period, post_period, prior_level_sd=None)\n",
    "    graph(ci, end_intervention_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted = ['S620','S638']\n",
    "experiment = 3\n",
    "intervention_data = interventions[experiment]\n",
    "for intervention in intervention_data[0]:\n",
    "    pre_period = intervention_data[1]\n",
    "    post_period = intervention_data[2]\n",
    "    end_intervention_date = intervention_data[3]\n",
    "    data = prepare_data(df, corrupted, intervention)\n",
    "    ci = CausalImpact(data, pre_period, post_period, prior_level_sd=None, standarize=True)\n",
    "    graph(ci, end_intervention_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
